Open google colab
create a new notebook 
helios_models.ipynb

run these 5 codes of ml models 

# CPU anomaly detection (Isolation Forest)
import numpy as np
from sklearn.ensemble import IsolationForest
import joblib
from google.colab import files
files.download("cpu_isoforest.pkl")


# Normal CPU: 5â€“60%, Anomalous CPU: 85â€“100%
X_normal = np.random.uniform(5, 60, (1000,1))
X_anom = np.random.uniform(85, 100, (50,1))
X = np.vstack([X_normal, X_anom])

model = IsolationForest(contamination=0.05, random_state=42)
model.fit(X)

joblib.dump(model, "cpu_isoforest.pkl")
print("Model saved: cpu_isoforest.pkl")

# Network traffic anomaly detection
import numpy as np
from sklearn.cluster import KMeans
import joblib
from google.colab import files
files.download("network_model.pkl")

# Simulate "requests per sec"
normal = np.random.poisson(100, (1000,1))
anom = np.random.poisson(500, (50,1))
X = np.vstack([normal, anom])

kmeans = KMeans(n_clusters=2, random_state=42).fit(X)
joblib.dump(kmeans, "network_model.pkl")
print("Model saved: network_model.pkl")

# Unauthorized login anomaly detection
import numpy as np
from sklearn.linear_model import LogisticRegression
import joblib
from google.colab import files
files.download("login_model.pkl")

# Features: [failed_attempts, time_of_day(0-23)]
X = np.array([
    [1,10],[2,11],[0,9],[1,22],[5,3],[6,2],[7,1],[10,23]
])
y = [0,0,0,0,1,1,1,1]  # 0 = legit, 1 = anomaly

clf = LogisticRegression().fit(X,y)
joblib.dump(clf,"login_model.pkl")
print("Model saved: login_model.pkl")

# Content injection detection
import joblib, re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from google.colab import files
files.download("content_model.pkl")

texts = [
    "hello how are you", 
    "click this http://spam.com",
    "check https://malware.biz",
    "this is safe text",
]
labels = [0,1,1,0]  # 0 = safe, 1 = anomaly

vec = TfidfVectorizer()
X = vec.fit_transform(texts)
clf = LogisticRegression().fit(X, labels)

joblib.dump((vec,clf),"content_model.pkl")
print("Model saved: content_model.pkl")

# Storage anomaly detection
import numpy as np
from sklearn.ensemble import IsolationForest
import joblib
from google.colab import files
files.download("storage_model.pkl")

# Normal growth: 100â€“300 MB, anomaly: sudden 1000 MB
X_normal = np.random.uniform(100,300,(1000,1))
X_anom = np.random.uniform(900,1000,(50,1))
X = np.vstack([X_normal,X_anom])

model = IsolationForest(contamination=0.05, random_state=42)
model.fit(X)

joblib.dump(model,"storage_model.pkl")
print("Model saved: storage_model.pkl")

RUN THESE FILES AND IT WILL INSTALL THESE FILES

storage_model.pkl
content_model.pkl
login_model.pkl
cpu_isoforest.pkl
network_model.pkl


Create a bucket 
helios-nitanshu 
Unselect "Block Public Access"
Enable Versioning

Create a folder models/
Upload all .pkl files to the models/ folder 

Create an instance
helios-agent
Create a .pem key pair 
attach a security group to the instance with SSH(22), HTTP(80), and Custom TCP(5000) ports with the CIDR of 0::0/0
 
Select the instance 
EC2 Instance Connect 
Connect
After entering the instance terminal 
run these codes 
sudo yum update -y
sudo yum install python3-pip -y
pip3 install flask boto3 scikit-learn joblib

Create Helios folder in ec2 instance terminal 
mkdir helios
cd helios
mkdir models

Create the IAM user with the policies of S3ReadOnlyAccess
access key- AKIAZKDIDKLQ2RXLMZO5
secret access key - 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

*THE ACCESS KEY NOW DEACTIVATED ALONG WITH THE USER

aws configure
Enter the IAM user keys
AWS Access Key ID: AKIAZKDIDKLQ2RXLMZO5
AWS Secret Access Key: gVMFv2WdYEduS2HFN6lxKvZSaC3Z48ZTPEs8i1XZ
Default region: us-east-1 (or your region)
Default output format: json

Check S3 access
aws s3 ls s3://helios-nitanshu/models/

Download models from S3 to EC2
cd ~/helios/models
aws s3 cp s3://helios-nitanshu/models/ . --recursive
ls  # You should see all 5 .pkl files

Create Flask App app.py
cd ~/helios
nano app.py
Paste your Flask code inside.
Save: CTRL+O â†’ Enter, Exit: CTRL+X

from flask import Flask, request, jsonify
import joblib
import os

app = Flask(__name__)

# Load models
models_path = os.path.join(os.getcwd(), "models")

cpu_model = joblib.load(os.path.join(models_path, "cpu_isoforest.pkl"))
network_model = joblib.load(os.path.join(models_path, "network_model.pkl"))
login_model = joblib.load(os.path.join(models_path, "login_model.pkl"))
storage_model = joblib.load(os.path.join(models_path, "storage_model.pkl"))

# Content model is a tuple (vectorizer, classifier)
content_vec, content_clf = joblib.load(os.path.join(models_path, "content_model.pkl"))

@app.route("/")
def home():
    return "Helios EC2 Agent Alive"

# CPU anomaly detection
@app.route("/predict/cpu", methods=["POST"])
def predict_cpu():
    data = request.json.get("value", 0)
    prediction = cpu_model.predict([[data]])[0]
    return jsonify({"cpu_value": data, "anomaly": int(prediction == -1)})

# Network anomaly detection
@app.route("/predict/network", methods=["POST"])
def predict_network():
    data = request.json.get("value", 0)
    prediction = network_model.predict([[data]])[0]
    return jsonify({"network_value": data, "anomaly": int(prediction == -1)})

# Login anomaly detection
@app.route("/predict/login", methods=["POST"])
def predict_login():
    data = request.json.get("value", [0, 0])  # [failed_attempts, time_of_day]
    prediction = login_model.predict([data])[0]
    return jsonify({"login_attempts": data, "anomaly": int(prediction == 1)})

# Content injection detection
@app.route("/predict/content", methods=["POST"])
def predict_content():
    text = request.json.get("text", "")
    X = content_vec.transform([text])
    prediction = content_clf.predict(X)[0]
    return jsonify({"text": text, "blocked": int(prediction == 1)})

# Storage anomaly detection
@app.route("/predict/storage", methods=["POST"])
def predict_storage():
    data = request.json.get("value", 0)
    prediction = storage_model.predict([[data]])[0]
    return jsonify({"storage_value": data, "anomaly": int(prediction == -1)})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)


Run Flask App
cd ~/helios
python3 app.py

# Make sure itâ€™s running:
curl http://127.0.0.1:5000/
# You should see: "Helios EC2 Agent Alive ðŸš€"

Update system
Install packages
Configure AWS CLI
Download models
Install Python libraries
Run Flask app (5000 first, then 80)
Port redirection via iptables
Curl tests & troubleshooting
Notes on logs & outside HTTP requests

for the correct sg group inbound rules
â€“
sgr-0c50bc36be41ddb13
IPv4
HTTPS
TCP
443
0.0.0.0/0
â€“
â€“
sgr-0c5ce7edadbe63ae0
IPv4
SSH
TCP
22
0.0.0.0/0
â€“
â€“
sgr-086e457d32373e22b
IPv4
HTTP
TCP
80
0.0.0.0/0
â€“
â€“
sgr-0ddd2f9c050982fab
IPv4
Custom TCP
TCP
5000
0.0.0.0/0
â€“


For a check of the models, go to POSTMAN 
select POST
1. CPU Anomaly
http://<EC2_IP>:5000/predict/cpu
{"value": 95}
Should return anomaly (1).
Try {"value": 40} â†’ normal (0).
2. Network Anomaly
http://<EC2_IP>:5000/predict/network
{"value": 600}
High traffic â†’ anomaly.
Try {"value": 100} â†’ normal.
3. Login Anomaly
http://<EC2_IP>:5000/predict/login
{"value": [6,2]}
6 failed logins at 2AM â†’ anomaly.
Try {"value": [1,10]} â†’ normal.
4. Content Injection
http://<EC2_IP>:5000/predict/content
{"text": "click http://spam.com"}
Should return blocked 1.
Try {"text": "hello friend"} â†’ blocked 0.
5. Storage Anomaly
http://<EC2_IP>:5000/predict/storage
{"value": 950}
Sudden 950MB usage â†’ anomaly.
Try {"value": 200} â†’ normal.

SO FAR, STUFF USED IS: AWS CONSOLE, EC2, S3, IAM, POSTMAN

1. Creating SNS Topic & Subscription
Go to SNS â†’ Topics â†’ Create Topic.
Name: HeliosAlerts.
Under Subscriptions, choose Email and enter your email ID.
Confirm subscription from the email you received.
Now any alert will ping your inbox.
2. Creating a CloudWatch Alarm
Go to CloudWatch â†’ Alarms â†’ Create Alarm.
Choose metric: EC2 â†’ CPUUtilization (for your instance).
Set threshold: Greater than 1% (so it easily triggers).
Select action: Send to SNS topic (HeliosAlerts).
Name the alarm: HeliosAlarm.
Now whenever CPU spikes, you get a real-time email alert.
3. Creating a CloudWatch Dashboard
Go to CloudWatch â†’ Dashboards â†’ Create Dashboard.
Name: HeliosDashboard.
Add widgets for:
CPUUtilization
NetworkIn
NetworkOut
DiskReadBytes / DiskWriteBytes
Save dashboard.
This gives you a live monitoring panel for anomalies.

For stressing your cpu model for testing 
sudo yum install -y stress-ng
stress-ng --cpu 2 --timeout 120s


Testing End-to-End Flow
Flask Agent Testing: Already done with Postman (all 5 endpoints tested).
CloudWatch Testing: Simulate CPU usage (e.g., run a heavy loop in EC2). Youâ€™ll see CPU spike in the dashboard.
Alert Testing: CloudWatch Alarm triggers â†’ SNS sends alert email (you already received one).
This proves the system is self-healing ready (detect â†’ alert â†’ react).

Tools & Services Used
Google Colab â†’ Training anomaly detection ML models.
AWS S3 â†’ Model storage & retrieval.
AWS EC2 â†’ Agent deployment with Flask API.
IAM â†’ Secure access control for EC2 â†” S3.
Postman â†’ Endpoint testing.
AWS CloudWatch â†’ Monitoring dashboards & alarms.
AWS SNS â†’ Real-time anomaly alerts via email.

Final Outcomes
Built 5 ML-driven anomaly detectors: CPU, Network, Login, Content Injection, Storage.
Integrated into a Flask API deployed on AWS EC2.
Enabled live monitoring via CloudWatch Dashboard.
Configured automatic alerts via SNS Email.

Demonstrated end-to-end anomaly detection & alert pipeline at zero cost using free tier.
